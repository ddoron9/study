{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"pose_estimator_torch.ipynb","provenance":[{"file_id":"10qPARjHr54x80TJkJzdZK1MThX0AM2Zx","timestamp":1614923465122}],"collapsed_sections":[],"authorship_tag":"ABX9TyNz5IdLSxUWUUXfE3So2On1"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnT9JvmC_e8O","executionInfo":{"status":"ok","timestamp":1615551431877,"user_tz":-540,"elapsed":270823,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}},"outputId":"9846777f-6a1f-4e4e-95ed-57b6c90ad870"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fb_ehyZTAhnS","executionInfo":{"status":"ok","timestamp":1615551432218,"user_tz":-540,"elapsed":271154,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}},"outputId":"fdbed17d-7600-4ddd-e3e0-a3da54d969bc"},"source":["cd drive/My Drive/data/open"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/data/open\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L26jA_NEhYbN","executionInfo":{"status":"ok","timestamp":1615551432219,"user_tz":-540,"elapsed":271149,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["import warnings\r\n","warnings.simplefilter(\"ignore\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTJU6275J_3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615551447596,"user_tz":-540,"elapsed":260,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}},"outputId":"272d3d65-628d-4ea2-963c-8975ba49521a"},"source":["!pip install albumentations\n","!pip install --upgrade albumentations\n","!pip install torchinfo "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Installing collected packages: torchinfo\n","Successfully installed torchinfo-0.0.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QCgJ_SGgDR77"},"source":["#Import"]},{"cell_type":"code","metadata":{"id":"kT8jcKcWCZJh","executionInfo":{"status":"ok","timestamp":1615551452403,"user_tz":-540,"elapsed":291329,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import torchvision\n","from torchvision import transforms\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim \n","from torchvision import datasets, models, transforms\n","from sklearn.model_selection import train_test_split\n","# For image-keypoints data augmentation\n","import albumentations as A\n","from albumentations.pytorch import ToTensor\n","import cv2 \n","import torch.onnx\n","import logging\n","import time\n","import copy\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DFeZuZKU0uZJ"},"source":["[Reproducable Code](https://hoya012.github.io/blog/reproducible_pytorch/)"]},{"cell_type":"code","metadata":{"id":"pRFdFYd10R7s","executionInfo":{"status":"ok","timestamp":1615551452404,"user_tz":-540,"elapsed":291327,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["random_seed = 42\n","\n","import random\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHUKczz0S6rn","executionInfo":{"status":"ok","timestamp":1615551452406,"user_tz":-540,"elapsed":291324,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["# logging.basicConfig(filename='./train.log', filemode='w',level=logging.INFO)\n","# logger = logging.getLogger()  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uk7O_DCXhpLA","executionInfo":{"status":"ok","timestamp":1615551523821,"user_tz":-540,"elapsed":816,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}},"outputId":"f30fefd0-c4a9-476b-d516-2a5bd2d139ac"},"source":["\n","\n","# Prefix data directory\n","prefix_dir = '.'\n","\n","# Top level data directory. Here we assume the format of the directory conforms\n","# to the ImageFolder structure\n","train_dir = f'{prefix_dir}/train_imgs'\n","\n","# Models to choose from torchvision\n","model_name = 'SoftGateModel' \n","\n","# Number of classes in the dataset\n","num_classes = 48\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 8\n","\n","# Number of epochs and earlystop to train for\n","num_epochs = 30\n","\n","num_splits = 20\n","num_earlystop = 20\n","\n","# Iput size for resize image\n","width =  512\n","height = 512\n","\n","\n","# Learning rate for optimizer\n","learning_rate = 0.01\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f'device name {device}')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["device name cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2mIrB6boTCiE"},"source":["#DataLoad"]},{"cell_type":"code","metadata":{"id":"tsi8KcAFq_ds","executionInfo":{"status":"ok","timestamp":1615551452408,"user_tz":-540,"elapsed":291312,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["# dir = os.listdir(train_dir)\n","# img = Image.open(os.path.join(train_dir,dir[0]))\n","# np.array(img).shape"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYArRd0vPnW4","executionInfo":{"status":"ok","timestamp":1615551453567,"user_tz":-540,"elapsed":292464,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}},"outputId":"46b3827a-efd3-43bf-8850-5542d63857ce"},"source":["df = pd.read_csv('train_df.csv') \n","imgs = df.iloc[:, 0].to_numpy()\n","motions = df.iloc[:, 1:]\n","columns = motions.columns.to_list()[::2]  \n","class_labels = [label.replace('_x', '').replace('_y', '') for label in columns] \n","keypoints = motions.to_numpy().reshape(-1,24,2) \n","keypoints.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4195, 24, 2)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"32vyWKQvR3uC","executionInfo":{"status":"ok","timestamp":1615551453568,"user_tz":-540,"elapsed":292463,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["\n","\n","# Data augmentation and normalization for training with Albumentations\n","A_transforms = {\n","    'train':\n","        A.Compose([\n","            A.augmentations.transforms.PadIfNeeded(min_height=1920, min_width=1920,border_mode=0),\n","            A.Resize(height, width, always_apply=True),\n","            A.OneOf([A.HorizontalFlip(p=1),\n","                     A.RandomRotate90(p=1),\n","                     A.VerticalFlip(p=1)            \n","            ], p=0.5),\n","            A.OneOf([A.MotionBlur(p=1),\n","                     A.GaussNoise(p=1)                 \n","            ], p=0.5),\n","            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","            ToTensor()],\\\n","            keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n","    'val':\n","        A.Compose([ \n","            A.augmentations.transforms.PadIfNeeded(min_height=1920, min_width=1920,border_mode=0),\n","            A.Resize(height, width, always_apply=True),\n","            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","            ToTensor()\n","        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n","    \n","    'test':\n","        A.Compose([ \n","            A.augmentations.transforms.PadIfNeeded(min_height=1920, min_width=1920,border_mode=0),\n","            A.Resize(height, width, always_apply=True),\n","            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","            ToTensor()\n","        ])\n","    ,\n","    'no_tf':\n","        A.Compose([\n","            A.augmentations.transforms.PadIfNeeded(min_height=1920, min_width=1920,border_mode=0),\n","            A.Resize(height, width, always_apply=True),\n","            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","            ToTensor()],\\\n","            keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n","   \n","}\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aMXobqhQbk5","executionInfo":{"status":"ok","timestamp":1615551453569,"user_tz":-540,"elapsed":292461,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["\n","class Dataset(torch.utils.data.Dataset):\n","    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n","    def __init__(self, \n","                 data_dir : \"image directory\",\n","                 imgs : \"x\", \n","                 keypoints : \"y\", \n","                 phase : \"train or val\", \n","                 class_labels : \"name of labels\"=None , \n","                 data_transforms=None):\n","        self.data_dir = data_dir\n","        self.imgs = imgs\n","        self.keypoints = keypoints\n","        self.phase = phase\n","        self.class_labels = class_labels\n","        self.data_transforms = data_transforms\n","\n","    def __getitem__(self, idx):\n","        # Read an image with OpenCV\n","        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n","        keypoints = self.keypoints[idx]\n","    \n","        if self.data_transforms:\n","            augmented = self.data_transforms[self.phase](image=img, keypoints=keypoints, class_labels=self.class_labels)\n","            img = augmented['image']\n","            keypoints = augmented['keypoints']\n","        keypoints = np.array(keypoints).flatten()\n","\n","        return img, keypoints\n","    \n","    def __len__(self):\n","        return len(self.imgs)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i3eUx3QqDX08"},"source":["#Model\n","keras의 padding same 을 활용하기 때문에 conv 및 maxpool 후 같은 크기로 만들어 준다. \n","\n","conv output = (input + 2p -k) / s + 1\n","if k = 3 -> p = 1 , s = 1\n","if k = 5 -> p = 2, s = 1\n","\n","maxpool output = (input + 2p - k) /s + 1"]},{"cell_type":"code","metadata":{"id":"hBhGSOUCpIJn","executionInfo":{"status":"ok","timestamp":1615551453569,"user_tz":-540,"elapsed":292458,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["class SoftGateModel(nn.Module):\n","    def __init__(self, width, height, num_classes):\n","        super(SoftGateModel, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(64,64, 3, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 1, 3, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.pool = nn.MaxPool2d(2)  \n","        self.upsample = nn.Upsample(scale_factor=2)\n","        self.relu = nn.ReLU()\n","        self.decode = nn.Sequential(\n","          self.conv2,\n","          self.relu,\n","          self.upsample\n","      )\n","        self.fc = nn.Linear(width * height, num_classes)\n","        \n","        self.width = width\n","        self.height = height\n","    def forward(self, x):\n","        # x = self.pool(F.relu(self.conv1(x))) \n","      x1 = self.conv1(x) \n","      x2 = self.conv2(self.pool(x1))\n","      x3 = self.conv2(self.pool(x2))\n","      x4 = self.conv2(self.pool(x3))\n","      encoded = self.pool(x4)\n","\n","      #decoding\n","      u0 = self.decode(encoded)\n","      w  = torch.add(u0,self.conv2(x4))\n","\n","      u1 = self.decode(w)   \n","      w  = torch.add(u1, self.conv2(x3))\n","\n","      u2 = self.decode(w)  \n","      w  = torch.add(u2, self.conv2(x2))\n","\n","      u3 = self.decode(w)  \n","      w  = torch.add(u3, self.conv2(x1))\n","\n","      decoded = self.conv3(w) \n","      out = decoded.view(-1, self.width * self.height)  \n","      out = self.fc(out)\n","\n","      return out\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"RNjGOgKeYlMo","executionInfo":{"status":"ok","timestamp":1615551463769,"user_tz":-540,"elapsed":302656,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["model = SoftGateModel(width, height, num_classes).to(device)\n","from torchinfo import summary\n","# summary(model, (16, 3,512,512))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TgwNoPzdniC","executionInfo":{"status":"ok","timestamp":1615551463771,"user_tz":-540,"elapsed":302656,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["\n","# Setup the loss fxn\n","criterion = nn.MSELoss()\n","# Observe that all parameters are being optimized\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate) \n","\n","X_train, X_val, y_train, y_val = train_test_split(imgs, keypoints, test_size=1/num_splits, random_state=random_seed)\n","\n","train_data = Dataset(train_dir, X_train, y_train, data_transforms=A_transforms, class_labels=class_labels, phase='train')\n","no_tf_train_data = Dataset(train_dir, X_train, y_train, data_transforms=A_transforms, class_labels=class_labels, phase='train')\n","val_data = Dataset(train_dir, X_val, y_val, data_transforms=A_transforms, class_labels=class_labels, phase='val')\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","no_tf_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","\n","dataloaders = {'train': train_loader, 'val': val_loader, 'no_tf': no_tf_loader} "],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gxvWJpufTI1y"},"source":["#Train"]},{"cell_type":"code","metadata":{"id":"Nnc5349v_lNe","executionInfo":{"status":"ok","timestamp":1615551463772,"user_tz":-540,"elapsed":302652,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["\n","\n","def train_model(model, dataloaders, criterion, optimizer, earlystop=0, num_epochs=25):\n","    since = time.time()\n","    \n","    val_acc_history = []\n","    val_loss_history = []\n","    earlystop_value = 0\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0\n","    best_loss = 999999999\n","    \n","    #scheduler\n","    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, \n","                                              T_mult=1, eta_min=0.00001)\n","    for epoch in range(num_epochs):\n","        epoch_since = time.time()\n","        if earlystop and earlystop_value >= earlystop:\n","            break\n","\n","        print('Epoch {}/{}'.format(epoch + 1, num_epochs), end=' ')\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val','no_tf']:\n","            if phase == 'val':\n","                model.eval()   # Set model to evaluate mode \n","            else:\n","                model.train()  # Set model to training mode\n","        \n","            running_loss = 0.0\n","            running_corrects = 0\n","            # Iterate over data.\n","            for i,(inputs, labels) in enumerate(dataloaders[phase]): \n","                inputs = inputs.to(device)\n","                labels = labels.to(device) \n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train' or phase == 'no_tf'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    outputs = model(inputs) \n","                    loss = criterion(outputs.float(), labels.float())\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train' or phase == 'no_tf':\n","                        if i % 30 == 0:\n","                          print('#',end='')\n","                        loss.backward()\n","                        optimizer.step()\n","                        scheduler.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                # for regression\n","                running_corrects += torch.sum(outputs == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","            \n","            epoch_time_elapsed = time.time() - epoch_since\n","            print('{} ({}) Loss: {:.4f} Elapsed time: {:.0f}m {:.0f}s'.format(\n","                phase, len(dataloaders[phase].dataset), epoch_loss, epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n","              \n","            # deep copy the model\n","            if phase == 'val':\n","                if epoch_loss < best_loss:\n","                    best_loss = epoch_loss\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                    earlystop_value = 0\n","                    torch.save(model.state_dict(), f'{prefix_dir}/models/{model_name}_val.pt')\n","                else:\n","                    earlystop_value += 1\n","                val_loss_history.append(epoch_loss)\n","                val_acc_history.append(epoch_acc)\n","\n","    time_elapsed = time.time() - since\n","    print('Training and Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best validation Acc: {:4f}\\n'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, {'acc': val_acc_history, 'loss': val_loss_history}\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4OviPvAJ3tZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f2e4e99-18c2-489f-90e1-180cfcdc7d34"},"source":["since = time.time()\n","\n","# Train and evaluate\n","model, hists = train_model(\n","    model, dataloaders, criterion, optimizer,\n","    num_epochs=num_epochs, earlystop=num_earlystop)\n","\n","torch.save(model.state_dict(), f'{prefix_dir}/models/{model_name}_best_model.pt')\n","time_elapsed = time.time() - since\n","\n","print('Elapsed time: {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30 #################train (3985) Loss: 2707.0461 Elapsed time: 31m 16s\n","val (210) Loss: 1423.6858 Elapsed time: 32m 45s\n","#################no_tf (3985) Loss: 1083.5811 Elapsed time: 39m 36s\n","Epoch 2/30 #################train (3985) Loss: 734.9625 Elapsed time: 6m 47s\n","val (210) Loss: 416.2091 Elapsed time: 6m 58s\n","#################no_tf (3985) Loss: 627.4568 Elapsed time: 13m 43s\n","Epoch 3/30 #################train (3985) Loss: 521.9095 Elapsed time: 6m 45s\n","val (210) Loss: 281.1134 Elapsed time: 6m 56s\n","#################no_tf (3985) Loss: 450.2137 Elapsed time: 13m 43s\n","Epoch 4/30 #################train (3985) Loss: 335.4170 Elapsed time: 6m 51s\n","val (210) Loss: 213.2727 Elapsed time: 7m 1s\n","#################no_tf (3985) Loss: 363.4924 Elapsed time: 13m 49s\n","Epoch 5/30 #################train (3985) Loss: 295.0937 Elapsed time: 6m 47s\n","val (210) Loss: 175.9058 Elapsed time: 6m 57s\n","#################no_tf (3985) Loss: 273.2380 Elapsed time: 13m 43s\n","Epoch 6/30 #################train (3985) Loss: 258.2671 Elapsed time: 6m 47s\n","val (210) Loss: 181.0814 Elapsed time: 6m 58s\n","#################no_tf (3985) Loss: 222.8078 Elapsed time: 13m 45s\n","Epoch 7/30 #################train (3985) Loss: 212.7031 Elapsed time: 6m 50s\n","val (210) Loss: 211.3225 Elapsed time: 7m 1s\n","#################no_tf (3985) Loss: 225.2703 Elapsed time: 13m 49s\n","Epoch 8/30 #################train (3985) Loss: 229.5052 Elapsed time: 6m 48s\n","val (210) Loss: 154.9939 Elapsed time: 6m 58s\n","#####"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gBhA0LSXAEjz","executionInfo":{"status":"aborted","timestamp":1615551502921,"user_tz":-540,"elapsed":341792,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["plt.figure(1)\n","plt.plot(hists.acc)\n","# plt.xlabel\n","plt.title('validation accuracy')\n","\n","plt.figure(2)\n","plt.plot(hists.loss)\n","# plt.xlabel\n","plt.title('validation loss')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfkqvMjYs9E1","executionInfo":{"status":"aborted","timestamp":1615551502923,"user_tz":-540,"elapsed":341791,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["\n","\n","def evaluate(model, dataloaders, criterion, optimizer):\n","    since = time.time()\n","    \n","    val_acc_history = []\n","    val_loss_history = []\n","    earlystop_value = 0\n","  \n","\n","    model.eval()   # Set model to evaluate mode\n","        \n","    running_loss = 0.0\n","    running_corrects = 0\n","    # Iterate over data.\n","    for inputs, labels in tqdm(dataloaders): \n","        inputs = inputs.to(device)\n","        labels = labels.to(device) \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs.float(), labels.float())\n","\n","            # statistics\n","        running_loss += loss.item() * inputs.size(0)\n","        # for regression\n","        running_corrects += torch.sum(outputs == labels.data) \n","\n","        epoch_loss = running_loss / len(dataloaders.dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n","        \n","        print(f'loss {epoch_loss} acc {epoch_acc}') \n","\n"," evaluate(\n","    model, dataloaders, criterion, optimizer)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6KdBMrKMTKw6"},"source":["#Test"]},{"cell_type":"code","metadata":{"id":"4Us6NBBLTOz7","executionInfo":{"status":"aborted","timestamp":1615551502926,"user_tz":-540,"elapsed":341792,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["test_dir = f'{prefix_dir}/test_imgs'\n","test_imgs = os.listdir(test_dir)\n","print(len(test_imgs), device)\n","model = SoftGateModel(width, height, num_classes).to(device) \n","model.load_state_dict(torch.load(f'{prefix_dir}/models/{model_name}_best_model.pt',map_location=device), strict=False) \n","model.eval() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSTLR8M9TOq3","executionInfo":{"status":"aborted","timestamp":1615551502926,"user_tz":-540,"elapsed":341790,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["class TestDataset(torch.utils.data.Dataset):\n","    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n","    def __init__(self, data_dir, imgs, phase, data_transforms=None):\n","        self.data_dir = data_dir\n","        self.imgs = imgs\n","        self.phase = phase\n","        self.data_transforms = data_transforms\n","\n","    def __getitem__(self, idx):\n","        filename = self.imgs[idx]\n","        # Read an image with OpenCV\n","        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n","\n","        if self.data_transforms:\n","            augmented = self.data_transforms[self.phase](image=img)\n","            img = augmented['image']\n","        return filename, img\n","    \n","    def __len__(self):\n","        return len(self.imgs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTQsS2JdUDYu","executionInfo":{"status":"aborted","timestamp":1615551502927,"user_tz":-540,"elapsed":341788,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["test_data = TestDataset(test_dir, test_imgs, data_transforms=A_transforms, phase='test')\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size * 4, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GUlgmrQURRi","executionInfo":{"status":"aborted","timestamp":1615551502928,"user_tz":-540,"elapsed":341787,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["all_predictions = []\n","files = []\n","with torch.no_grad():\n","    for filenames, inputs in tqdm(test_loader):\n","        predictions = list(model(inputs.to(device)).cpu().numpy())\n","        files.extend(filenames)\n","        all_predictions.extend(predictions)\n","all_predictions = np.array(all_predictions)\n","for i in range(all_predictions.shape[0]):\n","    all_predictions[i, [2*j for j in range(num_classes//2)]] /= width / 1920\n","    all_predictions[i, [2*j + 1 for j in range(num_classes//2)]] /= height / 1080\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QIjpG30PTPDz"},"source":["#Submission"]},{"cell_type":"code","metadata":{"id":"SS8CrO0DUb11","executionInfo":{"status":"aborted","timestamp":1615551502928,"user_tz":-540,"elapsed":341784,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["df_sub = pd.read_csv(f'{prefix_dir}/sample_submission.csv')\n","df = pd.DataFrame(columns=df_sub.columns)\n","df['image'] = files\n","df.iloc[:, 1:] = all_predictions\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MSymFPqEUegx","executionInfo":{"status":"aborted","timestamp":1615551502929,"user_tz":-540,"elapsed":341782,"user":{"displayName":"도비","photoUrl":"https://lh3.googleusercontent.com/-mFzWI9qyYb0/AAAAAAAAAAI/AAAAAAAAGWQ/8wg4bis6NG4/s64/photo.jpg","userId":"09983640273426569595"}}},"source":["df.to_csv(f'{prefix_dir}/submission_{model_name}.csv', index=False)"],"execution_count":null,"outputs":[]}]}